FROM ubuntu:noble

# docker build -f Dockerfile.cuda -t llama_cpp_server .

RUN apt update && apt install -y git git-lfs

RUN git clone https://github.com/ZalozbaDev/llama.cpp /llama.cpp_b4458 && cd llama.cpp_b4458 && git checkout b4458

RUN apt install -y cmake g++ nvidia-cuda-toolkit nvidia-utils-535-server=535.216.03-0ubuntu0.24.04.1

RUN cd llama.cpp_b4458 && cmake -B build -DGGML_CUDA=ON && cmake --build build -j --config Release

RUN mkdir /model

COPY startme.sh /

RUN chmod 755 /startme.sh

CMD ["/startme.sh"]
